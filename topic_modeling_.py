# -*- coding: utf-8 -*-
"""Topic Modeling .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nR_j-SnL6WFTEUPy7ji0K_aecQtcw6Un
"""

from gensim import corpora , similarities , models
from nltk.tokenize import sent_tokenize  , word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.tag import pos_tag
import nltk
from nltk.corpus import stopwords
from operator import itemgetter
import re
import csv
import pprint

nltk.download("punkt")
nltk.download("stopwords")
nltk.download("averaged_perceptron_tagger")
nltk.download("wordnet")
nltk.download('omw-1.4')

!pip install wikipedia
import wikipedia

wikipage  = wikipedia.page("Coronavirus").content
print(wikipage)

# Sentence Tokenization
wiki_sent = sent_tokenize(wikipage)
print(wiki_sent)

# Word Tokenization
wiki_words = []
for sent in wiki_sent:
  wiki_words.extend(word_tokenize(sent))
print(wiki_words)

# POS Tagging
tagged = pos_tag(wiki_words)
print(tagged)

from nltk.corpus import wordnet
def getpos(treebank_tag):

  if treebank_tag.startswith('J'):
    return wordnet.ADJ
  elif treebank_tag.startswith('V'):
    return wordnet.VERB
  elif treebank_tag.startswith('N'):
    return wordnet.NOUN
  elif treebank_tag.startswith('R'):
    return wordnet.ADV
  else:
    return ''

# Lemmatization with pos
punctuation = u",.?!()-\"\'\\+<>#&$^|/"
stop_words_eng = set(stopwords.words('english'))
wordnet_lemmatizer = WordNetLemmatizer()
lemma_pos = []
for word , tag in tagged:
  if word not in punctuation and word not in stop_words_eng and word.isalpha():
    p = getpos(tag)
    if p != '':
      l = wordnet_lemmatizer.lemmatize(word , pos = p)
      lemma_pos.append(l)
print(lemma_pos)

id2word = corpora.Dictionary([lemma_pos])
texts = lemma_pos
corpus = [id2word.doc2bow([text]) for text in texts]

n_topics = 5
lda_model = models.LdaModel(corpus = corpus , 
                            id2word = id2word,
                            num_topics = 5,
                            random_state=100,
                            update_every=1,
                            chunksize = 100,
                            passes = 10,
                            alpha  = 'symmetric',
                            per_word_topics = True                  
                            )
print(lda_model.print_topics())

import pyLDAvis
import pyLDAvis.gensim_models as gensimvis
pyLDAvis.enable_notebook()

# feed the LDA model into the pyLDAvis instance
lda_viz = gensimvis.prepare(lda_model, corpus, id2word)
lda_viz











